{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import langdetect\n",
    "import glob\n",
    "nlp = spacy.load('en')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from gensim.models.phrases import Phrases,Phraser\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = list(set(stopwords.words('english')))\n",
    "import random\n",
    "from modules import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawled = pd.read_csv(\"./data/crawl_data(7379 pages - employment-social-development).csv\").drop_duplicates(subset=[\"text\"], keep=\"first\")\n",
    "crawled[\"lang\"] = crawled.text.apply(lambda x: langdetect.detect(str(x)))\n",
    "crawled = crawled[crawled[\"lang\"] == \"en\"].text;len(crawled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = crawled.str.cat(sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_clean = re.sub('[^a-zA-Z0-9\\s\\.]+', '', corpus).lower()\n",
    "corpus_clean = re.sub(\"\\s{2,}\",\" \",corpus_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_clean[:800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = sent_tokenize(corpus_clean)\n",
    "sents = list(set(sents))\n",
    "sents = [re.sub('[^a-zA-Z0-9\\s]+', '', sent) for sent in sents];len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random.choice(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_stream = [sent.split() for sent in sents];sents_stream[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate N-Grams From Co-Occuring Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"default\" scoring: <i>from “Efficient Estimaton of Word Representations in Vector Space” by\n",
    "Mikolov, et. al.: (count(worda followed by wordb) - min_count) * N / (count(worda) * count(wordb)) > threshold`, where N is the total vocabulary size.</i>\n",
    "\n",
    "\n",
    "\"npmi\" scoring: <i>normalized pointwise mutual information, from “Normalized (Pointwise) Mutual\n",
    "Information in Colocation Extraction” by Gerlof Bouma: ln(prop(worda followed by wordb) / (prop(worda)*prop(wordb))) / - ln(prop(worda followed by wordb) where prop(n) is the count of n / the count of everything in the entire corpus.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n_gram_transformers(stream,n_gram = 3,scoring=\"default\",min_count=5,threshold=10,common_terms=None):\n",
    "    streams = [stream]    \n",
    "    grams = [stream]\n",
    "    for n in range(1,n_gram):\n",
    "        gram = Phraser(Phrases(streams[-1],scoring=scoring,min_count=min_count,threshold=threshold,common_terms=common_terms))\n",
    "        streams.append(list(gram[streams[-1]]))\n",
    "        grams.append(gram)\n",
    "        \n",
    "    return grams\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,to_bigrams,to_trigrams,to_quadgrams = generate_n_gram_transformers(sents_stream,n_gram=4,\n",
    "                                                   scoring=\"default\",min_count=30,\n",
    "                                                   threshold=10,common_terms=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_sent_stream = \"employment and social development canada service canada is serving canadians to have better lives\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_bigrams[ex_sent_stream]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_trigrams[to_bigrams[ex_sent_stream]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_quadgrams[to_trigrams[to_bigrams[ex_sent_stream]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_stream = list(to_quadgrams[to_trigrams[to_bigrams[sents_stream]]])\n",
    "tri_stream = list(to_trigrams[to_bigrams[sents_stream]])\n",
    "quad_sents = [' '.join(sent) for sent in quad_stream]\n",
    "tri_sents = [' '.join(sent) for sent in tri_stream]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choice(quad_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD2VEC_EMBEDDING_DIM = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(quad_stream, size=WORD2VEC_EMBEDDING_DIM, window=12, min_count=30, workers=4,iter=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(\"requirement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format(\"./data/word2vec_esdc.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embeddings = utils.load_embedding_model(\"/Users/WASSIMATHIMNI/data/embeddings/glove/glove.6B.100d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10545, 400000)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vocab.keys()),len(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sidecar Approach - Concatenate Corpus Specific Trained Embeddings to General Pretrained Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCAT_DIM = PRETRAINED_DIM+WORD2VEC_EMBEDDING_DIM\n",
    "concat_embeddings = {}\n",
    "for key,vec in pretrained_embeddings.items():\n",
    "    if key in model.wv.vocab:\n",
    "        concat_embeddings[key] = np.hstack((vec,model.wv[key]))\n",
    "    else:\n",
    "        concat_embeddings[key] = np.hstack((vec,np.zeros(WORD2VEC_EMBEDDING_DIM)))\n",
    "for key in model.wv.vocab.keys():\n",
    "    if key not in concat_embeddings:\n",
    "        concat_embeddings[key] = np.hstack((np.zeros(PRETRAINED_DIM),model.wv[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"hockey\" in concat_embeddings,\"service_canada\" in concat_embeddings,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.30817  ,  0.30938  ,  0.52803  , -0.92543  , -0.73671  ,\n",
       "        0.63475  ,  0.44197  ,  0.10262  , -0.09142  , -0.56607  ,\n",
       "       -0.5327   ,  0.2013   ,  0.7704   , -0.13983  ,  0.13727  ,\n",
       "        1.1128   ,  0.89301  , -0.17869  , -0.0019722,  0.57289  ,\n",
       "        0.59479  ,  0.50428  , -0.28991  , -1.3491   ,  0.42756  ,\n",
       "        1.2748   , -1.1613   , -0.41084  ,  0.042804 ,  0.54866  ,\n",
       "        0.18897  ,  0.3759   ,  0.58035  ,  0.66975  ,  0.81156  ,\n",
       "        0.93864  , -0.51005  , -0.070079 ,  0.82819  , -0.35346  ,\n",
       "        0.21086  , -0.24412  , -0.16554  , -0.78358  , -0.48482  ,\n",
       "        0.38968  , -0.86356  , -0.016391 ,  0.31984  , -0.49246  ,\n",
       "       -0.069363 ,  0.018869 , -0.098286 ,  1.3126   , -0.12116  ,\n",
       "       -1.2399   , -0.091429 ,  0.35294  ,  0.64645  ,  0.089642 ,\n",
       "        0.70294  ,  1.1244   ,  0.38639  ,  0.52084  ,  0.98787  ,\n",
       "        0.79952  , -0.34625  ,  0.14095  ,  0.80167  ,  0.20987  ,\n",
       "       -0.86007  , -0.15308  ,  0.074523 ,  0.40816  ,  0.019208 ,\n",
       "        0.51587  , -0.34428  , -0.24525  , -0.77984  ,  0.27425  ,\n",
       "        0.22418  ,  0.20164  ,  0.017431 , -0.014697 , -1.0235   ,\n",
       "       -0.39695  , -0.0056188,  0.30569  ,  0.31748  ,  0.021404 ,\n",
       "        0.11837  , -0.11319  ,  0.42456  ,  0.53405  , -0.16717  ,\n",
       "       -0.27185  , -0.6255   ,  0.12883  ,  0.62529  , -0.52086  ,\n",
       "        0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "        0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "        0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "        0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "        0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "        0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "        0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "        0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "        0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "        0.       ,  0.       ,  0.       ,  0.       ,  0.       ])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_embeddings[\"dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_closest_embeddings(word,embeddings,num_results=10):\n",
    "    keys =  [key for key,_ in embeddings.items()]\n",
    "    embs =  [emb for _,emb in embeddings.items()]\n",
    "    \n",
    "\n",
    "    distances = distance.cdist(embs,[embeddings[word]])\n",
    "    \n",
    "    closest_idx = sorted(range(len(distances)),key=lambda k : distances[k])\n",
    "    \n",
    "    results = [(keys[idx],distances[idx][0]) for idx in closest_idx[:num_results]]\n",
    "    return results[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"security\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('safeguarding', 0.6965300440788269),\n",
       " ('holdings', 0.6321510076522827),\n",
       " ('privacy_and_security', 0.6195051074028015),\n",
       " ('sensitive', 0.6101369261741638),\n",
       " ('privacy', 0.5911946296691895),\n",
       " ('retention', 0.5894044637680054),\n",
       " ('integrity', 0.5829138159751892),\n",
       " ('protocols', 0.5738561153411865),\n",
       " ('management', 0.5725846886634827),\n",
       " ('protection', 0.572011411190033)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('officials', 4.5959739965486675),\n",
       " ('military', 4.618754130871209),\n",
       " ('personnel', 4.637935129688064),\n",
       " ('enforcement', 4.697978849367469),\n",
       " ('civilian', 4.737160836506255),\n",
       " ('control', 4.789275243116566),\n",
       " ('special', 4.791420784860835),\n",
       " ('administration', 4.818851646703397),\n",
       " ('government', 4.873565346693941)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_closest_embeddings(word,pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on concatenated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('safeguarding', 14.322703175552572),\n",
       " ('privacy_and_security', 15.323617480407206),\n",
       " ('sensitive', 15.462598341415253),\n",
       " ('holdings', 15.501257884537067),\n",
       " ('safeguard', 15.570697252166168),\n",
       " ('social_insurance_register', 15.85231032336952),\n",
       " ('risk_management', 15.921606275469456),\n",
       " ('monitors', 16.0446182458727),\n",
       " ('stewardship', 16.081221737471804)]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_closest_embeddings(word,concat_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/WASSIMATHIMNI/data/embeddings/glove/esdc_glove_150d.vec\",'w',encoding=\"utf-8\") as f:\n",
    "    for key,emb in concat_embeddings.items():\n",
    "        f.write('{} {}\\n'.format(str(key),' '.join([str(num) for num in emb])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
